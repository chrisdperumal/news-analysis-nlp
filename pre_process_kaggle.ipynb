{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy_download import load_spacy\n",
    "\n",
    "\n",
    "# Will download the model if it isn't installed yet\n",
    "nlp = load_spacy(\"en_core_web_lg\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('./News_Category_Dataset_v3.json', encoding='utf-8', lines=True)\n",
    "df['cleaned_text'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I decided to merge similar categories to improve accuracy\n",
    "df.category = df.category.map(lambda x: \"WORLDPOST\" if x == \"THE WORLDPOST\" else x)\n",
    "df.category = df.category.map(lambda x: \"ARTS & CULTURE\" if x == \"ARTS\" else x)\n",
    "df.category = df.category.map(lambda x: \"ARTS & CULTURE\" if x == \"CULTURE & ARTS\" else x)\n",
    "df.category = df.category.map(lambda x: \"STYLE & BEAUTY\" if x == \"STYLE\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df.groupby('category')\n",
    "num_topics = categories.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to improve accuracy by combining headline and short description\n",
    "df['text'] = df.headline + \" \" + df.short_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_document(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must do some nlp processing to improve the topic modeling\n",
    "# it looks like the topics generated used a lot of stop words\n",
    "# aded a lemmatization step for better accuracy\n",
    "df['cleaned_text'] = df['text'].apply(pre_process_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('cleaned_kaggle_data.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e508abc5b6f001e1f0869bacd66542349052afec2d331b74eaf6def03e428003"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
